{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8be6738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraper is running with a stealth configuration!\n",
      "Using IP from proxy and User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from selenium_stealth import stealth\n",
    "from selenium import webdriver\n",
    "# --- 1. User-Agent Setup ---\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\",\n",
    "]\n",
    "random_user_agent = random.choice(USER_AGENTS)\n",
    "\n",
    "# --- 2. Proxy Setup ---\n",
    "# Note: Replace USERNAME and PASSWORD with your actual credentials\n",
    "#proxy_options = {\n",
    "#    'proxy': {\n",
    "#        'no_proxy': 'localhost,127.0.0.1' # Bypasses proxy for local traffic\n",
    "#    }\n",
    "#}\n",
    "\n",
    "# --- 3. Chrome Options Setup ---\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(f\"--user-agent={random_user_agent}\")\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "# chrome_options.add_argument(\"--headless\") # Commented out to see the browser\n",
    "chrome_options.add_argument(\"--lang=en-US,en;q=0.9\")\n",
    "\n",
    "# Basic anti-detection options\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "# Load only DOM content\n",
    "#chrome_options.page_load_strategy = 'eager' \n",
    "\n",
    "# Initialize driver with selenium-wire\n",
    "driver = webdriver.Chrome(\n",
    "    options=chrome_options,\n",
    "    #seleniumwire_options=proxy_options\n",
    ")\n",
    "\n",
    "# --- 4. Stealth Setup ---\n",
    "stealth(driver,\n",
    "        languages=[\"en-US\", \"en\"],\n",
    "        vendor=\"Google Inc.\",\n",
    "        platform=\"Win32\",\n",
    "        webgl_vendor=\"Intel Inc.\",\n",
    "        renderer=\"Intel Iris OpenGL Engine\",\n",
    "        fix_hairline=True,\n",
    "        )\n",
    "\n",
    "# --- 5. Run the Scraper ---\n",
    "print(\"Scraper is running with a stealth configuration!\")\n",
    "print(f\"Using IP from proxy and User-Agent: {random_user_agent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad12ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import json\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4407245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Refactored Store Scraping Functions with Try-Catch ####\n",
    "\n",
    "def get_filtered_products(products_details, word_to_search):\n",
    "    \"\"\"\n",
    "    Filter products for relevance based on search term\n",
    "    Returns: list of relevant products\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    search_term_lower = word_to_search.lower()\n",
    "    \n",
    "    for p in products_details:\n",
    "        title_lower = p[\"name\"].lower()\n",
    "        if search_term_lower in title_lower:\n",
    "            filtered.append(p)\n",
    "            \n",
    "    return filtered\n",
    "\n",
    "\n",
    "def scrape_al_fateh(driver, word_to_search, wait_time=10):\n",
    "    \"\"\"\n",
    "    Scrape Al-Fatah store for products\n",
    "    Returns: list of products with store name, or empty list on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        store_name = \"Al-Fateh\"\n",
    "        AL_FATEH_GROCERY_URL = f\"https://alfatah.pk/search?q={word_to_search}\"\n",
    "        \n",
    "        driver.get(AL_FATEH_GROCERY_URL)\n",
    "        wait = WebDriverWait(driver, wait_time)\n",
    "        \n",
    "        product_cards = wait.until(EC.presence_of_all_elements_located(\n",
    "            (By.CSS_SELECTOR, \".col-6.col-sm-4.col-md-3.col-lg-2\")\n",
    "        ))\n",
    "        \n",
    "        products_details = []\n",
    "        for product in product_cards:\n",
    "            try:\n",
    "                a_element = product.find_element(By.CSS_SELECTOR, \"a[class='product-title-ellipsis']\")\n",
    "                product_link = a_element.get_attribute(\"href\")\n",
    "                product_name = a_element.text\n",
    "                product_price= product.find_element(By.CLASS_NAME, \"product-price\").text\n",
    "                products_details.append({\n",
    "                    \"store\": store_name,\n",
    "                    \"name\": product_name,\n",
    "                    \"link\": product_link,\n",
    "                    \"price\": product_price\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"[{store_name}] Error extracting product: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Filter for relevance\n",
    "        filtered_products = get_filtered_products(products_details, word_to_search)\n",
    "        \n",
    "        print(f\"[{store_name}] Found {len(filtered_products)} relevant products\")\n",
    "        return filtered_products\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Al-Fateh] Error during scraping: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def scrape_metro(driver, word_to_search, wait_time=10):\n",
    "    \"\"\"\n",
    "    Scrape Metro store for products with name and price\n",
    "    Returns: list of products with store name, or empty list on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        store_name = \"Metro\"\n",
    "        METRO_GROCERY_URL = f\"https://www.metro-online.pk/search/{word_to_search}?searchText={word_to_search}\"\n",
    "        \n",
    "        driver.get(METRO_GROCERY_URL)\n",
    "        #wait = WebDriverWait(driver, wait_time)\n",
    "        \n",
    "        # Search for product\n",
    "        #input_box = wait.until(EC.presence_of_element_located(\n",
    "         #   (By.CLASS_NAME, \"newNavbar_nav_search__LBtcn\")\n",
    "        #))\n",
    "        #input_box.clear()\n",
    "       # input_box.send_keys(word_to_search)\n",
    "        input_box.send_keys(Keys.RETURN)\n",
    "        \n",
    "        # Get product cards\n",
    "        product_cards = wait.until(EC.presence_of_all_elements_located(\n",
    "            (By.CLASS_NAME, \"CategoryGrid_product_card__FUMXW\")\n",
    "        ))\n",
    "\n",
    "        products_details = []\n",
    "\n",
    "        for product_card in product_cards:\n",
    "            try:\n",
    "                product_link=product_card.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                name = product_card.find_element(By.CLASS_NAME, \"CategoryGrid_product_name__3nYsN\").text\n",
    "                price = product_card.find_element(By.CLASS_NAME, \"CategoryGrid_product_price__Svf8T\").text\n",
    "                products_details.append({\n",
    "                        \"store\": store_name,\n",
    "                        \"name\": name,\n",
    "                        \"link\": product_link,\n",
    "                        \"price\": price\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"[{store_name}] Error extracting product details: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        # Filter for relevance\n",
    "        filtered_products = get_filtered_products(products_details, word_to_search)\n",
    "\n",
    "        print(f\"[{store_name}] Found {len(filtered_products)} products\")\n",
    "        return filtered_products\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Metro] Error during scraping: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def scrape_jalalsons(driver, word_to_search, wait_time=10):\n",
    "    \"\"\"\n",
    "    Scrape Jalal Sons store for products with name and price\n",
    "    Returns: list of products with store name, or empty list on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        store_name = \"Jalal Sons\"\n",
    "        JALALSONS_GROCERY_URL = f\"https://jalalsons.com.pk/shop?query={word_to_search}\"\n",
    "        \n",
    "        driver.get(JALALSONS_GROCERY_URL)\n",
    "        wait = WebDriverWait(driver, wait_time)\n",
    "        \n",
    "        # Close banner if present\n",
    "        try:\n",
    "            banner_close_button = wait.until(EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, \".cursor-pointer.ms-auto\")\n",
    "            ))\n",
    "            banner_close_button.click()\n",
    "        except TimeoutException:\n",
    "            print(f\"[{store_name}] No banner appeared\")\n",
    "        \n",
    "        # Select location from dropdown\n",
    "        try:\n",
    "            from selenium.webdriver.support.ui import Select\n",
    "            location_dropdown = wait.until(EC.presence_of_element_located(\n",
    "                (By.ID, \"selectDeliveryBranch\")\n",
    "            ))\n",
    "            select_object = Select(location_dropdown)\n",
    "            all_options = select_object.options\n",
    "            \n",
    "            enabled_options = [\n",
    "                opt for opt in all_options\n",
    "                if opt.is_enabled() and opt.get_attribute('value') != \"\"\n",
    "            ]\n",
    "            \n",
    "            if enabled_options:\n",
    "                random_option = random.choice(enabled_options)\n",
    "                select_object.select_by_visible_text(random_option.text)\n",
    "                \n",
    "                try:\n",
    "                    submit_button = driver.find_element(By.CLASS_NAME, \"current_loc_pop_btn\")\n",
    "                    submit_button.click()\n",
    "                except Exception as e:\n",
    "                    print(f\"[{store_name}] No button to confirm location selection: {str(e)}\")\n",
    "        except:\n",
    "            print(f\"[{store_name}] No location box appeared\")\n",
    "        \n",
    "        # Get products\n",
    "        product_cards = wait.until(EC.presence_of_all_elements_located(\n",
    "            (By.CLASS_NAME, \"single_product_theme\")\n",
    "        ))\n",
    "\n",
    "        products_details = []\n",
    "\n",
    "        for product_card in product_cards:\n",
    "            try:\n",
    "                product_link = product_card.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                name=product_card.find_element(By.CLASS_NAME, \"product_name_theme\").text\n",
    "                currency=product_card.find_element(By.CLASS_NAME, \"item-currency\").text\n",
    "                price=product_card.find_element(By.CLASS_NAME, \"price-value\").text\n",
    "                products_details.append({\n",
    "                    \"store\": store_name,\n",
    "                    \"name\": name,\n",
    "                    \"link\": product_link,\n",
    "                    \"price\": f\"{currency} {price}\"\n",
    "                })\n",
    "       \n",
    "            except Exception as e:\n",
    "                print(f\"[{store_name}] Error extracting product details: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        filtered_products = get_filtered_products(products_details, word_to_search)\n",
    "        print(f\"[{store_name}] Found {len(filtered_products)} products\")\n",
    "        return filtered_products\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Jalal Sons] Error during scraping: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def scrape_carrefour(driver, word_to_search, wait_time=10):\n",
    "    \"\"\"\n",
    "    Scrape Carrefour store for products with name and price\n",
    "    Returns: list of products with store name, or empty list on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        store_name = \"Carrefour\"\n",
    "        CAREFOUR_GROCERY_URL = f\"https://www.carrefour.pk/mafpak/en/search?keyword={word_to_search}\"\n",
    "        \n",
    "        driver.get(CAREFOUR_GROCERY_URL)\n",
    "        wait = WebDriverWait(driver, wait_time)\n",
    "        \n",
    "        product = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, \"/html/body/div[1]/main/div/div[2]/div[2]/div/div[2]/div/div\")\n",
    "        ))\n",
    "        \n",
    "        \n",
    "        \n",
    "        product_links = set()\n",
    "        for link in product.find_elements(By.TAG_NAME, \"a\"):\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if href:\n",
    "                product_links.add(href)\n",
    "\n",
    "        products_details = []\n",
    "        for link in product_links:\n",
    "            try:\n",
    "                driver.get(link)\n",
    "                name = driver.find_element(\n",
    "                    By.XPATH, \"/html/body/div[1]/main/div/div[3]/div/div[2]/h1\"\n",
    "                ).text\n",
    "                price = driver.find_element(\n",
    "                    By.XPATH, \"/html/body/div[1]/main/div/div[3]/div/div[3]/div[1]/div[1]\"\n",
    "                ).text\n",
    "                \n",
    "                products_details.append({\n",
    "                    \"store\": store_name,\n",
    "                    \"name\": name,\n",
    "                    \"link\": link,\n",
    "                    \"price\": price\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"[{store_name}] Error extracting product details: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        filtered_products = get_filtered_products(products_details, word_to_search)\n",
    "        print(f\"[{store_name}] Found {len(filtered_products)} products\")\n",
    "        return filtered_products\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Carrefour] Error during scraping: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def scrape_imtiaz(driver, word_to_search, wait_time=2):\n",
    "    \"\"\"\n",
    "    Scrape Imtiaz store for products\n",
    "    Returns: list of products with store name, or empty list on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        store_name = \"Imtiaz\"\n",
    "        IMTIAZ_GROCERY_URL = f\"https://shop.imtiaz.com.pk/search?q={word_to_search}\"\n",
    "        \n",
    "        driver.get(IMTIAZ_GROCERY_URL)\n",
    "        wait = WebDriverWait(driver, wait_time)\n",
    "        \n",
    "        # Select location\n",
    "        try:\n",
    "            area = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, \"/html/body/div[2]/div[3]/div/div/div/div/div[3]/div[3]/div/div/input\")\n",
    "            ))\n",
    "            area.send_keys(Keys.ENTER)\n",
    "            area.send_keys(Keys.DOWN)\n",
    "            area.send_keys(Keys.DOWN)\n",
    "            area.send_keys(Keys.ENTER)\n",
    "            \n",
    "            submit_button = wait.until(EC.presence_of_element_located(\n",
    "                (By.XPATH, \"/html/body/div[2]/div[3]/div/div/div/div/div[3]/button\")\n",
    "            ))\n",
    "            submit_button.click()\n",
    "        except TimeoutException:\n",
    "            print(f\"[{store_name}] No location box appeared\")\n",
    "        \n",
    "        # Get products\n",
    "        try:\n",
    "            products = wait.until(EC.presence_of_all_elements_located(\n",
    "                (By.CSS_SELECTOR, \".hazle-product-item_product_item__FSm1N.MuiBox-root.blink-style-5bkk4b\")\n",
    "            ))\n",
    "            \n",
    "            products_details = []\n",
    "            for product in products:\n",
    "                try:\n",
    "                    # Extract product info from the element\n",
    "                    # Note: Adjust selectors based on actual HTML structure\n",
    "                    product_info = product.text\n",
    "                    if product_info:\n",
    "                        products_details.append({\n",
    "                            \"store\": store_name,\n",
    "                            \"name\": product_info,\n",
    "                            \"price\": \"\"\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"[{store_name}] Error extracting product info: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"[{store_name}] Found {len(products_details)} products\")\n",
    "            return products_details\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print(f\"[{store_name}] No products found\")\n",
    "            return []\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Imtiaz] Error during scraping: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# ===== MAIN SCRAPING FUNCTION =====\n",
    "def scrape_all_stores(driver, word_to_search):\n",
    "    \"\"\"\n",
    "    Scrape all 5 stores and combine results into a single list\n",
    "    Returns: list of all products from all stores with store names\n",
    "    \"\"\"\n",
    "    all_products = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting scraping for: '{word_to_search}'\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Scrape each store\n",
    "    stores_scrapers = [\n",
    "        (\"Al-Fateh\", scrape_al_fateh),\n",
    "        (\"Metro\", scrape_metro),\n",
    "        (\"Jalal Sons\", scrape_jalalsons),\n",
    "        (\"Carrefour\", scrape_carrefour),\n",
    "        (\"Imtiaz\", scrape_imtiaz),\n",
    "    ]\n",
    "    \n",
    "    for store_label, scraper_func in stores_scrapers:\n",
    "        print(f\"\\n[SCRAPING {store_label.upper()}]\")\n",
    "        try:\n",
    "            products = scraper_func(driver, word_to_search)\n",
    "            all_products.extend(products)\n",
    "        except Exception as e:\n",
    "            print(f\"FATAL ERROR for {store_label}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scraping Complete!\")\n",
    "    print(f\"Total products collected: {len(all_products)}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return all_products\n",
    "\n",
    "\n",
    "# ===== USAGE EXAMPLE =====\n",
    "# Uncomment below to run the scraper\n",
    "#word_to_search = \"pepsi\"\n",
    "#all_collected_products = scrape_all_stores(driver, word_to_search)\n",
    "#print(all_collected_products)\n",
    "#with open(f\"{word_to_search}_products.json\", \"w\") as f:\n",
    "    #json.dump(all_collected_products, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba72552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_scroll(driver):\n",
    "    #infinte scroll to load all products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(2, 5))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efb8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import json\n",
    "\n",
    "all_products = []\n",
    "STORE_NAME=\"jalal-sons\"\n",
    "JALAL_SONS_URL = \"https://jalalsons.com.pk/\"\n",
    "\n",
    "try:\n",
    "        store_name = \"Jalal Sons\"\n",
    "        JALALSONS_GROCERY_URL = f\"https://jalalsons.com.pk/shop?query={word_to_search}\"\n",
    "        \n",
    "        driver.get(JALALSONS_GROCERY_URL)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        \n",
    "        # Close banner if present\n",
    "        try:\n",
    "            banner_close_button = wait.until(EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, \".cursor-pointer.ms-auto\")\n",
    "            ))\n",
    "            banner_close_button.click()\n",
    "        except TimeoutException:\n",
    "            print(f\"[{store_name}] No banner appeared\")\n",
    "        \n",
    "        # Select location from dropdown\n",
    "        try:\n",
    "            from selenium.webdriver.support.ui import Select\n",
    "            location_dropdown = wait.until(EC.presence_of_element_located(\n",
    "                (By.ID, \"selectDeliveryBranch\")\n",
    "            ))\n",
    "            select_object = Select(location_dropdown)\n",
    "            all_options = select_object.options\n",
    "            \n",
    "            enabled_options = [\n",
    "                opt for opt in all_options\n",
    "                if opt.is_enabled() and opt.get_attribute('value') != \"\"\n",
    "            ]\n",
    "            \n",
    "            if enabled_options:\n",
    "                random_option = random.choice(enabled_options)\n",
    "                select_object.select_by_visible_text(random_option.text)\n",
    "                \n",
    "                try:\n",
    "                    submit_button = driver.find_element(By.CLASS_NAME, \"current_loc_pop_btn\")\n",
    "                    submit_button.click()\n",
    "                except Exception as e:\n",
    "                    print(f\"[{store_name}] No button to confirm location selection: {str(e)}\")\n",
    "        except:\n",
    "            print(f\"[{store_name}] No location box appeared\")\n",
    "        \n",
    "\n",
    "        #build a action chain to move to dropdown and perform\n",
    "        from selenium.webdriver.common.action_chains import ActionChains\n",
    "        actions=ActionChains(driver)\n",
    "        location_dropdown=driver.find_element(By.XPATH, \"/html/body/header[3]/div/nav/div[1]/ul/li[8]\")\n",
    "        actions.move_to_element(location_dropdown)\n",
    "        actions.perform()\n",
    "        \n",
    "        categories_box=wait.until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, \"drop-sub-links\"))\n",
    "        )\n",
    "        category_boxes=categories_box.find_elements(By.TAG_NAME, \"a\")\n",
    "        category_boxes_links = [box.get_attribute(\"href\") for box in category_boxes]\n",
    "        categories = [box.text.strip() for box in category_boxes]\n",
    "    \n",
    "\n",
    "        for category_link, CATEGORY_NAME in zip(category_boxes_links, categories):\n",
    "   \n",
    "            time.sleep(random.uniform(2, 7))\n",
    "            #click on the category\n",
    "            driver.get(category_link)\n",
    "           \n",
    "            # Get products\n",
    "            wait.until(EC.presence_of_all_elements_located(\n",
    "                (By.CLASS_NAME, \"single_product_theme\")\n",
    "            ))\n",
    "            infinite_scroll(driver)\n",
    "            product_cards = wait.until(EC.presence_of_all_elements_located(\n",
    "                (By.CLASS_NAME, \"single_product_theme\")\n",
    "            ))\n",
    "\n",
    "            for product_card in product_cards:\n",
    "                try:\n",
    "                    product_link = product_card.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                    name=product_card.find_element(By.CLASS_NAME, \"product_name_theme\").text.strip()\n",
    "                    currency=product_card.find_element(By.CLASS_NAME, \"item-currency\").text.strip()\n",
    "                    price=product_card.find_element(By.CLASS_NAME, \"price-value\").text.strip()\n",
    "                    all_products.append({\n",
    "                        \"store\": store_name,\n",
    "                        \"name\": name,\n",
    "                        \"product_link\": product_link,\n",
    "                        \"price\": f\"{currency} {price}\",\n",
    "                        \"category\":CATEGORY_NAME.strip(),\n",
    "                    })\n",
    "        \n",
    "                except Exception as e:\n",
    "                    print(f\"[{store_name}] Error extracting product details: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "            print (f\"Category '{CATEGORY_NAME}': Found {len(product_cards)} products\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    driver.save_screenshot(\"error_screenshot.png\")\n",
    "\n",
    "finally:\n",
    "    pass\n",
    "    # Save to JSON\n",
    "    with open(f\"{STORE_NAME}-products.json\", \"w\") as f:\n",
    "        json.dump(all_products, f, indent=4)\n",
    "    #driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_jalalsons(driver, \"pepsi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f0da07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>product_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Ice Cream</td>\n",
       "      <td>MOVENPICK ICE CREAM VANILLA DREAM 500ML</td>\n",
       "      <td>Rs.4,345</td>\n",
       "      <td>https://alfatah.pk/products/movenpick-ice-crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Frozen Items</td>\n",
       "      <td>PEETZA HOUR CHICKITA 570 GM</td>\n",
       "      <td>Rs.2,395</td>\n",
       "      <td>https://alfatah.pk/products/peetza-hour-chicki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Frozen Fries</td>\n",
       "      <td>MANO SALWA CHICKEN FRIES 425 GM</td>\n",
       "      <td>Rs.399</td>\n",
       "      <td>https://alfatah.pk/products/mano-salwa-chicken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Jams</td>\n",
       "      <td>SHEZAN JAM MIXED FRUIT 370 GM</td>\n",
       "      <td>Rs.275</td>\n",
       "      <td>https://alfatah.pk/products/shezan-jam-mixed-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Rice Products</td>\n",
       "      <td>GUARD ULTIMATE BASMATI RICE 5 KG</td>\n",
       "      <td>Rs.2,695</td>\n",
       "      <td>https://alfatah.pk/products/guard-ultimate-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Honey</td>\n",
       "      <td>YOUNGS NATURAL HONEY BEE HIVES 500 GM</td>\n",
       "      <td>Rs.895</td>\n",
       "      <td>https://alfatah.pk/products/youngs-natural-hon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Biscuits</td>\n",
       "      <td>FLAIR KUNAFA BROWNIES BAR 50GM</td>\n",
       "      <td>Rs.415</td>\n",
       "      <td>https://alfatah.pk/products/flair-kunafa-brown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>NESCAFE CLASSIC COFFE SACHET 50 GM</td>\n",
       "      <td>Rs.695</td>\n",
       "      <td>https://alfatah.pk/products/nescafe-classic-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Baking Items</td>\n",
       "      <td>RAFHAN VANILLA ICE CREAM POWDER 275 GM</td>\n",
       "      <td>Rs.210</td>\n",
       "      <td>https://alfatah.pk/products/rafhan-vanilla-ice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5065</th>\n",
       "      <td>al-fateh</td>\n",
       "      <td>Baking Accessories</td>\n",
       "      <td>COOKIE PRESS ICING SET TAILL</td>\n",
       "      <td>Rs.1,395</td>\n",
       "      <td>https://alfatah.pk/products/cookie-press-icing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         store            category                                     name  \\\n",
       "6106  al-fateh           Ice Cream  MOVENPICK ICE CREAM VANILLA DREAM 500ML   \n",
       "1330  al-fateh        Frozen Items              PEETZA HOUR CHICKITA 570 GM   \n",
       "1433  al-fateh        Frozen Fries          MANO SALWA CHICKEN FRIES 425 GM   \n",
       "5541  al-fateh                Jams            SHEZAN JAM MIXED FRUIT 370 GM   \n",
       "1712  al-fateh       Rice Products         GUARD ULTIMATE BASMATI RICE 5 KG   \n",
       "5470  al-fateh               Honey    YOUNGS NATURAL HONEY BEE HIVES 500 GM   \n",
       "2304  al-fateh            Biscuits           FLAIR KUNAFA BROWNIES BAR 50GM   \n",
       "4464  al-fateh              Coffee       NESCAFE CLASSIC COFFE SACHET 50 GM   \n",
       "5145  al-fateh        Baking Items   RAFHAN VANILLA ICE CREAM POWDER 275 GM   \n",
       "5065  al-fateh  Baking Accessories             COOKIE PRESS ICING SET TAILL   \n",
       "\n",
       "         price                                       product_link  \n",
       "6106  Rs.4,345  https://alfatah.pk/products/movenpick-ice-crea...  \n",
       "1330  Rs.2,395  https://alfatah.pk/products/peetza-hour-chicki...  \n",
       "1433    Rs.399  https://alfatah.pk/products/mano-salwa-chicken...  \n",
       "5541    Rs.275  https://alfatah.pk/products/shezan-jam-mixed-f...  \n",
       "1712  Rs.2,695  https://alfatah.pk/products/guard-ultimate-bas...  \n",
       "5470    Rs.895  https://alfatah.pk/products/youngs-natural-hon...  \n",
       "2304    Rs.415  https://alfatah.pk/products/flair-kunafa-brown...  \n",
       "4464    Rs.695  https://alfatah.pk/products/nescafe-classic-co...  \n",
       "5145    Rs.210  https://alfatah.pk/products/rafhan-vanilla-ice...  \n",
       "5065  Rs.1,395  https://alfatah.pk/products/cookie-press-icing...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Baby food                   161\n",
      "Baking Accessories          126\n",
      "Baking Chocolates            24\n",
      "Baking Items                182\n",
      "Biscuits                    622\n",
      "Bread                        54\n",
      "Butter                       45\n",
      "Candies & Bubble Gums       459\n",
      "Cereals                     176\n",
      "Cheese                      153\n",
      "Chips & Nimko               368\n",
      "Chocolates                  301\n",
      "Coffee                      122\n",
      "Dairy Creams                 20\n",
      "Drinking Powders             48\n",
      "Drinking water               49\n",
      "Dry Fruits & Dates          177\n",
      "Eggs                          9\n",
      "Flavoured Milk               27\n",
      "Flour                        60\n",
      "Frozen Fries                 28\n",
      "Frozen Items                538\n",
      "Ghee                         42\n",
      "Honey                        78\n",
      "Ice Cream                    82\n",
      "Imported Drinks & Juices    193\n",
      "Jams                         68\n",
      "Liquid Tin Milk               9\n",
      "Local Drinks                319\n",
      "Margarine                    14\n",
      "Mayo & Spreads              163\n",
      "Milk                         36\n",
      "Milk Powder & Whitener       28\n",
      "Noodles & Pasta             203\n",
      "Oils                        104\n",
      "Olive oil                    91\n",
      "Pickle & Vinegar            192\n",
      "PopCorn                      68\n",
      "Raita                         5\n",
      "Rice Products                64\n",
      "Rusks & Buns                 20\n",
      "Salt                         41\n",
      "Sauces & Soups              275\n",
      "Squashes                     43\n",
      "Sugar                         9\n",
      "Teas                        164\n",
      "Tin Foods                   174\n",
      "Yogurt                       27\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"al-fateh-products.json\")\n",
    "\n",
    "display(df.sample(10))\n",
    "\n",
    "print(df.groupby(\"category\").size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_venv)",
   "language": "python",
   "name": "my_venv_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
